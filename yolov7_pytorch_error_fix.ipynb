{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD9gUQpaBxNa"
      },
      "source": [
        "# How to Train YOLOv7 on a Custom Dataset\n",
        "\n",
        "This tutorial is based on the [YOLOv7 repository](https://github.com/WongKinYiu/yolov7) by WongKinYiu. This notebook shows training on **your own custom objects**. Many thanks to WongKinYiu and AlexeyAB for putting this repository together.\n",
        "\n",
        "\n",
        "### **Accompanying Blog Post**\n",
        "\n",
        "We recommend that you follow along in this notebook while reading the blog post on [how to train YOLOv7](https://blog.roboflow.com/yolov7-custom-dataset-training-tutorial/), concurrently.\n",
        "\n",
        "### **Steps Covered in this Tutorial**\n",
        "\n",
        "To train our detector we take the following steps:\n",
        "\n",
        "* Install YOLOv7 dependencies\n",
        "* Load custom dataset from Roboflow in YOLOv7 format\n",
        "* Run YOLOv7 training\n",
        "* Evaluate YOLOv7 performance\n",
        "* Run YOLOv7 inference on test images\n",
        "* OPTIONAL: Deployment\n",
        "* OPTIONAL: Active Learning\n",
        "\n",
        "\n",
        "## Roboflow Universe\n",
        "\n",
        "Need data for your project? Before spending time on annotating, check out Roboflow Universe, a repository of more than 200,000 open-source datasets that you can use in your projects. You'll find datasets containing everything from annotated cracks in concrete to plant images with disease annotations.\n",
        "\n",
        "\n",
        "[![Roboflow Universe](https://media.roboflow.com/notebooks/template/uni-banner-frame.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672878480290)](https://universe.roboflow.com/)\n",
        "\n",
        "## Preparing a custom dataset\n",
        "\n",
        "Building a custom dataset can be a painful process. It might take dozens or even hundreds of hours to collect images, label them, and export them in the proper format. Fortunately, Roboflow makes this process as straightforward and fast as possible. Let me show you how!\n",
        "\n",
        "### Step 1: Creating project\n",
        "\n",
        "Before you start, you need to create a Roboflow [account](https://app.roboflow.com/login). Once you do that, you can create a new project in the Roboflow [dashboard](https://app.roboflow.com/). Keep in mind to choose the right project type. In our case, Object Detection.\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img\n",
        "    width=\"640\"\n",
        "    src=\"https://media.roboflow.com/preparing-custom-dataset-example/creating-project.gif?ik-sdk-version=javascript-1.4.3&updatedAt=1672929799852\"\n",
        "  >\n",
        "</div>\n",
        "\n",
        "### Step 2: Uploading images\n",
        "\n",
        "Next, add the data to your newly created project. You can do it via API or through our [web interface](https://docs.roboflow.com/adding-data/object-detection).\n",
        "\n",
        "If you drag and drop a directory with a dataset in a supported format, the Roboflow dashboard will automatically read the images and annotations together.\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img\n",
        "    width=\"640\"\n",
        "    src=\"https://media.roboflow.com/preparing-custom-dataset-example/uploading-images.gif?ik-sdk-version=javascript-1.4.3&updatedAt=1672929808290\"\n",
        "  >\n",
        "</div>\n",
        "\n",
        "### Step 3: Labeling\n",
        "\n",
        "If you only have images, you can label them in [Roboflow Annotate](https://docs.roboflow.com/annotate).\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img\n",
        "    width=\"640\"\n",
        "    src=\"https://user-images.githubusercontent.com/26109316/210901980-04861efd-dfc0-4a01-9373-13a36b5e1df4.gif\"\n",
        "  >\n",
        "</div>\n",
        "\n",
        "### Step 4: Generate new dataset version\n",
        "\n",
        "Now that we have our images and annotations added, we can Generate a Dataset Version. When Generating a Version, you may elect to add preprocessing and augmentations. This step is completely optional, however, it can allow you to significantly improve the robustness of your model.\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img\n",
        "    width=\"640\"\n",
        "    src=\"https://media.roboflow.com/preparing-custom-dataset-example/generate-new-version.gif?ik-sdk-version=javascript-1.4.3&updatedAt=1673003597834\"\n",
        "  >\n",
        "</div>\n",
        "\n",
        "### Step 5: Exporting dataset\n",
        "\n",
        "Once the dataset version is generated, we have a hosted dataset we can load directly into our notebook for easy training. Click `Export` and select the `YOLO v5 PyTorch` dataset format.\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img\n",
        "    width=\"640\"\n",
        "    src=\"https://media.roboflow.com/preparing-custom-dataset-example/export.gif?ik-sdk-version=javascript-1.4.3&updatedAt=1672943313709\"\n",
        "  >\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "#Install Dependencies\n",
        "\n",
        "_(Remember to choose GPU in Runtime if not already selected. Runtime --> Change Runtime Type --> Hardware accelerator --> GPU)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JGJspIl90XhV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86b83a98-93dd-42b1-c159-3fd7f6d9f1d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Mar 27 21:30:40 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   67C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nD-uPyQ_2jiN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f2c4d77-717f-4d68-9b47-aa2c34d8e781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov7'...\n",
            "remote: Enumerating objects: 579, done.\u001b[K\n",
            "remote: Total 579 (delta 0), reused 0 (delta 0), pack-reused 579 (from 1)\u001b[K\n",
            "Receiving objects: 100% (579/579), 38.53 MiB | 24.43 MiB/s, done.\n",
            "Resolving deltas: 100% (281/281), done.\n",
            "/content/yolov7\n",
            "Branch 'fix/problems_associated_with_the_latest_versions_of_pytorch_and_numpy' set up to track remote branch 'fix/problems_associated_with_the_latest_versions_of_pytorch_and_numpy' from 'origin'.\n",
            "Switched to a new branch 'fix/problems_associated_with_the_latest_versions_of_pytorch_and_numpy'\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (2.0.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (4.11.0.86)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (11.1.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (1.14.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (4.67.1)\n",
            "Collecting protobuf<4.21.3 (from -r requirements.txt (line 14))\n",
            "  Downloading protobuf-4.21.2-cp37-abi3-manylinux2014_x86_64.whl.metadata (540 bytes)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (2.18.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (0.13.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 34)) (7.34.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 35)) (5.9.5)\n",
            "Collecting thop (from -r requirements.txt (line 36))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.7)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.1.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2025.1)\n",
            "Collecting jedi>=0.16 (from ipython->-r requirements.txt (line 34))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 34)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 34)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 34)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 34)) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 34)) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 34)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 34)) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->-r requirements.txt (line 34)) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->-r requirements.txt (line 34)) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->-r requirements.txt (line 34)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 34)) (0.2.13)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m111.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.21.2-cp37-abi3-manylinux2014_x86_64.whl (407 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.8/407.8 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jedi, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.4\n",
            "    Uninstalling protobuf-5.29.4:\n",
            "      Successfully uninstalled protobuf-5.29.4\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-cloud-bigquery-connection 1.18.2 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-language 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-aiplatform 1.84.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-spanner 3.53.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-api-core 2.24.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-bigtable 2.30.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "grpc-google-iam-v1 0.14.2 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 4.21.2 which is incompatible.\n",
            "googleapis-common-protos 1.69.2 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-iam 2.18.3 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.29.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-datastore 2.20.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-functions 1.20.2 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-dataproc 5.18.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-pubsub 2.29.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-translate 3.20.2 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-resource-manager 1.14.2 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\n",
            "google-cloud-firestore 2.20.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 4.21.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jedi-0.19.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 protobuf-4.21.2 thop-0.1.1.post2209072238\n"
          ]
        }
      ],
      "source": [
        "# Download YOLOv7 repository and install requirements\n",
        "\n",
        "# !git clone https://github.com/WongKinYiu/yolov7\n",
        "# %cd yolov7\n",
        "# !pip install -r requirements.txt\n",
        "\n",
        "# current version of YOLOv7 is not compatible with pytorch>1.12.1 and numpy>1.20.1\n",
        "# until the appropriate changes get made to the main repository, we will be using a fork containing the patched code\n",
        "# you can track the progress here: https://github.com/roboflow/notebooks/issues/27\n",
        "!git clone https://github.com/SkalskiP/yolov7.git\n",
        "%cd yolov7\n",
        "!git checkout fix/problems_associated_with_the_latest_versions_of_pytorch_and_numpy\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtJ24mPlyF-S"
      },
      "source": [
        "# Download Correctly Formatted Custom Data\n",
        "\n",
        "Next, we'll download our dataset in the right format. Use the `YOLOv7 PyTorch` export. Note that this model requires YOLO TXT annotations, a custom YAML file, and organized directories. The roboflow export writes this for us and saves it in the correct spot.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ovKgrVN8ygdW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac232c19-1640-4bb5-f039-c2b385be5ebb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.58-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.1.31)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.0.2)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.1.0)\n",
            "Collecting pillow-heif>=0.18.0 (from roboflow)\n",
            "  Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.3.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.56.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.1)\n",
            "Downloading roboflow-1.1.58-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m112.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: filetype, python-dotenv, pillow-heif, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.11.0.86\n",
            "    Uninstalling opencv-python-headless-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-headless-4.11.0.86\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pillow-heif-0.22.0 python-dotenv-1.1.0 roboflow-1.1.58\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Facial-emotion-recognition-1 to yolov7pytorch:: 100%|██████████| 188477/188477 [00:02<00:00, 64217.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Facial-emotion-recognition-1 in yolov7pytorch:: 100%|██████████| 10144/10144 [00:01<00:00, 7173.55it/s]\n"
          ]
        }
      ],
      "source": [
        "# REPLACE with your custom code snippet generated above\n",
        "\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"EHOn7R5Jmi11PxeMpSMH\")\n",
        "project = rf.workspace(\"university-f1igv\").project(\"facial-emotion-recognition-uyeby\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov7\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHfT9gEiBsBd"
      },
      "source": [
        "# Begin Custom Training\n",
        "\n",
        "We're ready to start custom training.\n",
        "\n",
        "NOTE: We will only modify one of the YOLOv7 training defaults in our example: `epochs`. We will adjust from 300 to 100 epochs in our example for speed. If you'd like to change other settings, see details in [our accompanying blog post](https://blog.roboflow.com/yolov7-custom-dataset-training-tutorial/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bUbmy674bhpD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87805e2c-647a-4196-8437-17ff924e5733"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7\n",
            "--2025-03-27 21:33:15--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/13e046d1-f7f0-43ab-910b-480613181b1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250327%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250327T213315Z&X-Amz-Expires=300&X-Amz-Signature=40ef8f34829df24ef13740b710d9151340378817571be272a06d1b49e26fcf70&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov7_training.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-03-27 21:33:15--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/13e046d1-f7f0-43ab-910b-480613181b1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250327%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250327T213315Z&X-Amz-Expires=300&X-Amz-Signature=40ef8f34829df24ef13740b710d9151340378817571be272a06d1b49e26fcf70&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dyolov7_training.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75628875 (72M) [application/octet-stream]\n",
            "Saving to: ‘yolov7_training.pt’\n",
            "\n",
            "yolov7_training.pt  100%[===================>]  72.12M  80.8MB/s    in 0.9s    \n",
            "\n",
            "2025-03-27 21:33:17 (80.8 MB/s) - ‘yolov7_training.pt’ saved [75628875/75628875]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download COCO starting checkpoint\n",
        "%cd /content/yolov7\n",
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.5.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2lMeOrMiJnl",
        "outputId": "00eb67b0-c570-4f90-86f4-fbc500a58bcd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.5.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.5.0%2Bcu118-cp311-cp311-linux_x86_64.whl (838.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m838.4/838.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch==2.5.0)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.0) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.21.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.20.1%2Bcu118-cp311-cp311-linux_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.20.0%2Bcu118-cp311-cp311-linux_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.5.1%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.5.0%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.0) (3.0.2)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 torch-2.5.0+cu118 torchaudio-2.5.0+cu118 torchvision-0.20.0+cu118 triton-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fileinput\n",
        "\n",
        "file_path = \"/content/yolov7/utils/general.py\"\n",
        "\n",
        "# Replace np.int with int\n",
        "with fileinput.FileInput(file_path, inplace=True, backup='.bak') as file:\n",
        "    for line in file:\n",
        "        print(line.replace(\"np.int\", \"int\"), end=\"\")\n",
        "\n",
        "print(\"✅ Fixed np.int issue in utils/general.py\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7WWcrdUjv90",
        "outputId": "22fa682e-44a8-4c94-b566-2dab34b95f15"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fixed np.int issue in utils/general.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1iqOPKjr22mL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f78513d3-aa20-4122-953a-4f5957113a98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov7\n",
            "2025-03-27 21:43:15.857164: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1743111795.878621    3713 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1743111795.885131    3713 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-27 21:43:15.907658: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "YOLOR 🚀 b2a7de9 torch 2.5.0+cu118 CUDA:0 (Tesla T4, 15095.0625MB)\n",
            "\n",
            "Namespace(weights='yolov7_training.pt', cfg='', data='/content/yolov7/Facial-emotion-recognition-1/data.yaml', hyp='data/hyp.scratch.p5.yaml', epochs=30, batch_size=16, img_size=[640, 640], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=8, project='runs/train', entity=None, name='exp', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/exp3', total_batch_size=16)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.0, paste_in=0.15, loss_ota=1\n",
            "/content/yolov7/train.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  run_id = torch.load(weights, map_location=device).get('wandb_id') if weights.endswith('.pt') and os.path.isfile(weights) else None\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmhaque221592\u001b[0m (\u001b[33mmhaque221592-united-international-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/yolov7/wandb/run-20250327_214323-chmgydjv\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mhaque221592-united-international-university/YOLOR\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mhaque221592-united-international-university/YOLOR/runs/chmgydjv\u001b[0m\n",
            "/content/yolov7/train.py:87: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ckpt = torch.load(weights, map_location=device)  # load checkpoint\n",
            "Overriding model.yaml nc=80 with nc=5\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            "  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            "  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 12                -1  1         0  models.common.MP                        []                            \n",
            " 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n",
            " 25                -1  1         0  models.common.MP                        []                            \n",
            " 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 38                -1  1         0  models.common.MP                        []                            \n",
            " 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n",
            " 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n",
            " 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n",
            " 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n",
            " 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n",
            " 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n",
            " 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n",
            " 76                -1  1         0  models.common.MP                        []                            \n",
            " 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n",
            " 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n",
            " 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n",
            " 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n",
            " 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            " 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n",
            " 89                -1  1         0  models.common.MP                        []                            \n",
            " 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n",
            " 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n",
            " 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n",
            " 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            " 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n",
            "100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n",
            "101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n",
            "102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n",
            "103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n",
            "104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n",
            "105   [102, 103, 104]  1     55732  models.yolo.IDetect                     [5, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "Model Summary: 415 layers, 37218132 parameters, 37218132 gradients, 105.2 GFLOPS\n",
            "\n",
            "Transferred 557/566 items from yolov7_training.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n",
            "/content/yolov7/utils/datasets.py:392: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  cache, exists = torch.load(cache_path), True  # load\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'Facial-emotion-recognition-1/train/labels.cache' images and labels... 3547 found, 0 missing, 2 empty, 0 corrupted: 100% 3547/3547 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning 'Facial-emotion-recognition-1/valid/labels.cache' images and labels... 1014 found, 0 missing, 0 empty, 1 corrupted: 100% 1014/1014 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 3.73, Best Possible Recall (BPR) = 1.0000\n",
            "/content/yolov7/train.py:299: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = amp.GradScaler(enabled=cuda)\n",
            "Image sizes 640 train, 640 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp3\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "  0% 0/222 [00:00<?, ?it/s]/content/yolov7/train.py:360: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with amp.autocast(enabled=cuda):\n",
            "      0/29     2.18G   0.06014   0.01186   0.02568   0.09768        22       640: 100% 222/222 [03:37<00:00,  1.02it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:28<00:00,  1.12it/s]\n",
            "                 all        1013        1155       0.369       0.384       0.301       0.153\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      1/29     12.9G   0.05824  0.009158   0.02285   0.09025        38       640: 100% 222/222 [03:15<00:00,  1.14it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:18<00:00,  1.75it/s]\n",
            "                 all        1013        1155       0.148       0.264       0.105      0.0484\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      2/29     12.5G   0.06071  0.008994   0.02285   0.09256        28       640: 100% 222/222 [03:12<00:00,  1.16it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:20<00:00,  1.54it/s]\n",
            "                 all        1013        1155     0.00258      0.0779    0.000254    4.58e-05\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      3/29     14.8G   0.06134  0.008739   0.02363   0.09371        23       640: 100% 222/222 [03:10<00:00,  1.16it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:18<00:00,  1.70it/s]\n",
            "                 all        1013        1155       0.129       0.218       0.107      0.0327\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      4/29     14.8G   0.05695  0.008453   0.02256   0.08796        32       640: 100% 222/222 [03:10<00:00,  1.17it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:17<00:00,  1.80it/s]\n",
            "                 all        1013        1155       0.184        0.41       0.196      0.0605\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      5/29     14.8G   0.05247   0.00825   0.02073   0.08145        23       640: 100% 222/222 [03:09<00:00,  1.17it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:20<00:00,  1.60it/s]\n",
            "                 all        1013        1155       0.278       0.507       0.284       0.119\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      6/29     14.8G     0.048  0.008234   0.01953   0.07577        30       640: 100% 222/222 [03:08<00:00,  1.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:18<00:00,  1.75it/s]\n",
            "                 all        1013        1155       0.291       0.415       0.278       0.114\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      7/29     14.8G   0.04978  0.008335   0.01967   0.07778        28       640: 100% 222/222 [03:08<00:00,  1.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:18<00:00,  1.72it/s]\n",
            "                 all        1013        1155       0.352       0.517       0.349       0.162\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      8/29     14.8G    0.0493  0.008405   0.01911   0.07682        33       640: 100% 222/222 [03:10<00:00,  1.16it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:19<00:00,  1.62it/s]\n",
            "                 all        1013        1155       0.285       0.519       0.312       0.134\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "      9/29     14.8G   0.04789  0.008066   0.01876   0.07472        39       640: 100% 222/222 [03:08<00:00,  1.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:17<00:00,  1.82it/s]\n",
            "                 all        1013        1155         0.3       0.578       0.353       0.166\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     10/29     14.8G   0.04646   0.00826   0.01847   0.07318        37       640: 100% 222/222 [03:09<00:00,  1.17it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:17<00:00,  1.80it/s]\n",
            "                 all        1013        1155       0.307       0.544       0.313       0.137\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     11/29     14.8G   0.04527  0.008345   0.01834   0.07196        34       640: 100% 222/222 [03:09<00:00,  1.17it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:19<00:00,  1.64it/s]\n",
            "                 all        1013        1155       0.455       0.542        0.44       0.224\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     12/29     14.8G   0.04431  0.008158   0.01789   0.07036        35       640: 100% 222/222 [03:08<00:00,  1.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:17<00:00,  1.81it/s]\n",
            "                 all        1013        1155       0.438       0.561       0.425       0.237\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     13/29     14.8G   0.04495  0.008059   0.01822   0.07124        27       640: 100% 222/222 [03:07<00:00,  1.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:17<00:00,  1.79it/s]\n",
            "                 all        1013        1155       0.452       0.568        0.46       0.258\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     14/29     14.8G   0.04371  0.007969   0.01737   0.06904        32       640: 100% 222/222 [03:07<00:00,  1.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:19<00:00,  1.60it/s]\n",
            "                 all        1013        1155       0.515       0.589       0.516        0.28\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     15/29     14.8G   0.04504  0.008044   0.01738   0.07047        46       640: 100% 222/222 [03:07<00:00,  1.19it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:17<00:00,  1.82it/s]\n",
            "                 all        1013        1155       0.455       0.587       0.493       0.261\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     16/29     14.8G   0.04679  0.008085   0.01801   0.07289        41       640: 100% 222/222 [03:07<00:00,  1.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:17<00:00,  1.80it/s]\n",
            "                 all        1013        1155       0.356       0.526       0.405       0.188\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     17/29     14.8G   0.04307  0.008181   0.01693   0.06818        41       640: 100% 222/222 [03:08<00:00,  1.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:19<00:00,  1.64it/s]\n",
            "                 all        1013        1155       0.494       0.625       0.523       0.283\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     18/29     14.8G   0.04261  0.008064   0.01707   0.06774        27       640: 100% 222/222 [03:07<00:00,  1.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:18<00:00,  1.71it/s]\n",
            "                 all        1013        1155       0.489       0.594        0.53       0.272\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     19/29     14.8G   0.04409  0.007953   0.01746   0.06951        24       640: 100% 222/222 [03:07<00:00,  1.19it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:19<00:00,  1.63it/s]\n",
            "                 all        1013        1155       0.509       0.609       0.556        0.31\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     20/29     14.8G   0.04209   0.00806   0.01686     0.067        27       640: 100% 222/222 [03:06<00:00,  1.19it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:19<00:00,  1.62it/s]\n",
            "                 all        1013        1155       0.531       0.552       0.525       0.275\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     21/29     14.8G    0.0422  0.007935   0.01689   0.06702        22       640: 100% 222/222 [03:07<00:00,  1.19it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:17<00:00,  1.82it/s]\n",
            "                 all        1013        1155       0.487       0.615       0.551       0.297\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     22/29     14.8G   0.04247  0.007917   0.01712   0.06751        25       640: 100% 222/222 [03:09<00:00,  1.17it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:19<00:00,  1.68it/s]\n",
            "                 all        1013        1155       0.484       0.635       0.544       0.287\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     23/29     14.8G   0.04228   0.00803   0.01722   0.06752        34       640: 100% 222/222 [03:09<00:00,  1.17it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:19<00:00,  1.65it/s]\n",
            "                 all        1013        1155       0.429       0.632       0.452       0.261\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     24/29     14.8G   0.04351  0.007958   0.01706   0.06853        36       640: 100% 222/222 [03:09<00:00,  1.17it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:18<00:00,  1.72it/s]\n",
            "                 all        1013        1155       0.514       0.653       0.588       0.331\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     25/29     14.8G    0.0454  0.007987    0.0178   0.07119        45       640: 100% 222/222 [03:08<00:00,  1.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:17<00:00,  1.82it/s]\n",
            "                 all        1013        1155       0.542       0.602       0.578        0.32\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     26/29     14.8G   0.04266  0.007956    0.0173   0.06792        34       640: 100% 222/222 [03:08<00:00,  1.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:19<00:00,  1.61it/s]\n",
            "                 all        1013        1155       0.536       0.614       0.602       0.334\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     27/29     14.8G   0.04343  0.007966   0.01728   0.06868        23       640: 100% 222/222 [03:07<00:00,  1.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:18<00:00,  1.76it/s]\n",
            "                 all        1013        1155        0.61       0.596       0.628       0.353\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     28/29     14.8G   0.04319  0.007993   0.01761   0.06879        35       640: 100% 222/222 [03:08<00:00,  1.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:17<00:00,  1.80it/s]\n",
            "                 all        1013        1155       0.567       0.634        0.63       0.356\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "     29/29     14.8G   0.04355  0.007872   0.01725   0.06867        22       640: 100% 222/222 [03:08<00:00,  1.18it/s]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 32/32 [00:23<00:00,  1.37it/s]\n",
            "                 all        1013        1155       0.621       0.598       0.635       0.359\n",
            "               angry        1013         228         0.9       0.649       0.794       0.633\n",
            "                fear        1013         179       0.605       0.642       0.672       0.367\n",
            "               happy        1013         281         0.6       0.571       0.571       0.226\n",
            "                 sad        1013         249       0.483       0.353       0.408        0.19\n",
            "           surprised        1013         218       0.517       0.775        0.73       0.382\n",
            "30 epochs completed in 1.785 hours.\n",
            "\n",
            "/content/yolov7/utils/general.py:802: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  x = torch.load(f, map_location=torch.device('cpu'))\n",
            "Optimizer stripped from runs/train/exp3/weights/last.pt, 74.8MB\n",
            "Optimizer stripped from runs/train/exp3/weights/best.pt, 74.8MB\n",
            "Images sizes do not match. This will causes images to be display incorrectly in the UI.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run_chmgydjv_model (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⢿\u001b[0m best.pt 8.2MB/71.4MB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run_chmgydjv_model (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣻\u001b[0m best.pt 8.2MB/71.4MB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run_chmgydjv_model (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣽\u001b[0m best.pt 8.2MB/71.4MB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run_chmgydjv_model (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣾\u001b[0m best.pt 8.2MB/71.4MB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run_chmgydjv_model (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣷\u001b[0m best.pt 8.2MB/71.4MB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run_chmgydjv_model (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣯\u001b[0m best.pt 8.2MB/71.4MB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run_chmgydjv_model (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⣟\u001b[0m best.pt 8.2MB/71.4MB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact run_chmgydjv_model (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⡿\u001b[0m best.pt 8.2MB/71.4MB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run_chmgydjv_model (1.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   ↳ \u001b[38;5;178m⢿\u001b[0m best.pt 8.2MB/71.4MB (0.7s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run_chmgydjv_model (2.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run_chmgydjv_model (2.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading artifact run_chmgydjv_model (2.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣷\u001b[0m uploading artifact run_chmgydjv_model (2.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣯\u001b[0m uploading artifact run_chmgydjv_model (2.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣟\u001b[0m uploading artifact run_chmgydjv_model (2.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⡿\u001b[0m uploading artifact run_chmgydjv_model (2.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⢿\u001b[0m uploading artifact run_chmgydjv_model (2.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣻\u001b[0m uploading artifact run_chmgydjv_model (2.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣽\u001b[0m uploading artifact run_chmgydjv_model (2.2s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading history steps 29-30, summary, console lines 281-293 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m⣾\u001b[0m uploading history steps 29-30, summary, console lines 281-293 (0.1s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 ▄▂▁▂▃▄▄▅▄▅▄▆▆▆▇▆▅▇▇▇▇▇▇▆▇▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 ▄▂▁▂▂▃▃▄▄▄▄▅▆▆▆▆▅▇▆▇▆▇▇▆▇▇████\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision ▅▃▁▂▃▄▄▅▄▄▄▆▆▆▇▆▅▇▇▇▇▆▆▆▇▇▇█▇█\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall ▅▃▁▃▅▆▅▆▆▇▇▇▇▇▇▇▆█▇▇▇████▇█▇█▇\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss █▇██▆▅▃▄▄▃▃▂▂▂▂▂▃▁▁▂▁▁▁▁▂▂▁▁▁▂\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss █▆▆▆▆▄▃▃▃▃▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▂▁▁▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss █▃▃▃▂▂▂▂▂▁▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss ▂▃█▅▅▅▄▃▃▃▃▃▂▃▃▃▃▃▂▂▂▂▁▂▁▁▁▁▂▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss ▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss ▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 ▂▄▆▇████▇▇▇▆▆▆▅▅▅▄▄▃▃▃▂▂▂▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 ▂▄▆▇████▇▇▇▆▆▆▅▅▅▄▄▃▃▃▂▂▂▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 █▆▄▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.63487\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.35942\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.62107\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.59822\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.04355\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.01725\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.00787\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.04884\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01656\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.00527\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.0011\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.0011\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.0011\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mexp3\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/mhaque221592-united-international-university/YOLOR/runs/chmgydjv\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/mhaque221592-united-international-university/YOLOR\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 342 media file(s), 2 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250327_214323-chmgydjv/logs\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# run this cell to begin training\n",
        "%cd /content/yolov7\n",
        "!python train.py --batch 16 --epochs 30 --data {dataset.location}/data.yaml --weights 'yolov7_training.pt' --device 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W0MpUaTCJro"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "We can evaluate the performance of our custom training using the provided evalution script.\n",
        "\n",
        "Note we can adjust the below custom arguments. For details, see [the arguments accepted by detect.py](https://github.com/WongKinYiu/yolov7/blob/main/detect.py#L154)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6AGhNOSSHY4_"
      },
      "outputs": [],
      "source": [
        "#display inference on ALL test images\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "i = 0\n",
        "limit = 10000 # max images to print\n",
        "for imageName in glob.glob('/content/yolov7/runs/detect/exp/*.jpg'): #assuming JPG\n",
        "    if i < limit:\n",
        "      display(Image(filename=imageName))\n",
        "      print(\"\\n\")\n",
        "    i = i + 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMOfi7eLJCT3"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/folder_name.zip /content/yolov7/runs/train/exp3 # Replace 'folder_name' with your desired zip file name\n",
        "from google.colab import files\n",
        "files.download('/content/folder_name.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMumI7a2JDAN"
      },
      "source": [
        "# Reparameterize for Inference\n",
        "\n",
        "https://github.com/WongKinYiu/yolov7/blob/main/tools/reparameterization.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqTktKURgnqM"
      },
      "source": [
        "## Deploy Model on Roboflow\n",
        "\n",
        "Once you have finished training your YOLOv7 model, you’ll have a set of trained weights ready for use. These weights will be in the `/content/runs/train/exp/weights/best.pt` folder of your project. You can upload your model weights to Roboflow Deploy to use your trained weights on our infinitely scalable infrastructure.\n",
        "\n",
        "The `.deploy()` function in the [Roboflow pip package](https://docs.roboflow.com/python) supports uploading YOLOv7 weights.\n",
        "\n",
        "**Before you run this code, make sure you create a new Version in the Roboflow dashboard following the instructions we covered earlier. Fill in your project name, workspace, and version number below.**\n",
        "\n",
        "[Learn how to retrieve your project ID](https://docs.roboflow.com/api-reference/workspace-and-project-ids)\n",
        "[Learn how to retrieve your API key.](https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7lNXeCbgnqM"
      },
      "outputs": [],
      "source": [
        "rf = Roboflow(api_key=\"YOUR_API_KEY\")\n",
        "project = rf.workspace(\"workspace\").project(\"project\")\n",
        "dataset = project.version(1)\n",
        "\n",
        "project.version(dataset.version).deploy(model_type=\"yolov7\", model_path=f\"/content/runs/train/exp/weights/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZX37S_LgnqM"
      },
      "source": [
        "# Deploy Your Model to the Edge\n",
        "\n",
        "In addition to using the Roboflow hosted API for deployment, you can use [Roboflow Inference](https://inference.roboflow.com), an open source inference solution that has powered millions of API calls in production environments. Inference works with CPU and GPU, giving you immediate access to a range of devices, from the NVIDIA Jetson to TRT-compatible devices to ARM CPU devices.\n",
        "\n",
        "With Roboflow Inference, you can self-host and deploy your model on-device. You can deploy applications using the [Inference Docker containers](https://inference.roboflow.com/quickstart/docker/) or the pip package.\n",
        "\n",
        "For example, to install Inference on a device with an NVIDIA GPU, we can use:\n",
        "\n",
        "```\n",
        "docker pull roboflow/roboflow-inference-server-gpu\n",
        "```\n",
        "\n",
        "Then we can run inference via HTTP:\n",
        "\n",
        "```python\n",
        "import requests\n",
        "\n",
        "workspace_id = \"\"\n",
        "model_id = \"\"\n",
        "image_url = \"\"\n",
        "confidence = 0.75\n",
        "api_key = \"\"\n",
        "iou_threshold = 0.5\n",
        "\n",
        "infer_payload = {\n",
        "    \"image\": {\n",
        "        \"type\": \"url\",\n",
        "        \"value\": image_url,\n",
        "    },\n",
        "    \"confidence\": confidence,\n",
        "    \"iou_threshold\": iou_threshold,\n",
        "    \"api_key\": api_key,\n",
        "}\n",
        "res = requests.post(\n",
        "    f\"http://localhost:9001/{workspace_id}/{model_id}\",\n",
        "    json=infer_object_detection_payload,\n",
        ")\n",
        "\n",
        "predictions = res.json()\n",
        "```\n",
        "\n",
        "Above, set your Roboflow workspace ID, model ID, and API key.\n",
        "\n",
        "- [Find your workspace and model ID](https://docs.roboflow.com/api-reference/workspace-and-project-ids?ref=blog.roboflow.com)\n",
        "- [Find your API key](https://docs.roboflow.com/api-reference/authentication?ref=blog.roboflow.com#retrieve-an-api-key)\n",
        "\n",
        "Also, set the URL of an image on which you want to run inference. This can be a local file.\n",
        "\n",
        "_To use your YOLOv5 model commercially with Inference, you will need a Roboflow Enterprise license, through which you gain a pass-through license for using YOLOv5. An enterprise license also grants you access to features like advanced device management, multi-model containers, auto-batch inference, and more._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVpCFeU-K4gb"
      },
      "source": [
        "# Next steps\n",
        "\n",
        "Congratulations, you've trained a custom YOLOv7 model! Next, start thinking about deploying and [building an MLOps pipeline](https://docs.roboflow.com) so your model gets better the more data it sees in the wild."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}